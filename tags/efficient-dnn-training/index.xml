<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Efficient DNN Training on Haoran You</title>
    <link>http://localhost:1313/tags/efficient-dnn-training/</link>
    <description>Recent content in Efficient DNN Training on Haoran You</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 12 Mar 2020 21:02:07 -0500</lastBuildDate>
    
	<atom:link href="http://localhost:1313/tags/efficient-dnn-training/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Efficient DNN Training</title>
      <link>http://localhost:1313/post/efficient-training/</link>
      <pubDate>Thu, 12 Mar 2020 21:02:07 -0500</pubDate>
      
      <guid>http://localhost:1313/post/efficient-training/</guid>
      <description>Efficient DNN Training Summary Model compression has been extensively studied for light-weight inference, popular means includes network pruning, weight factorization, network quantization, and neural architecture search among many others. On the other hand, the literature on efficient training appears to be much sparser, DNN training still requires us to fully train the over-parameterized neural network. Here we focus on reducing total training times and training energy cost, aiming at the deployment on resource-constrainted platforms, e.</description>
    </item>
    
    <item>
      <title>[ICLR 2020] Drawing Early-Bird Tickets: Towards More Efficient Training of Neural Networks</title>
      <link>http://localhost:1313/publication/early-bird/</link>
      <pubDate>Wed, 02 Oct 2019 18:03:59 -0500</pubDate>
      
      <guid>http://localhost:1313/publication/early-bird/</guid>
      <description>Accepted as spotlight oral paper! Abstract: (Frankle &amp;amp; Carbin, 2019) shows that there exist winning tickets (small but critical subnetworks) for dense, randomly initialized networks, that can be trained alone to achieve comparable accuracies to the latter in a similar number of iterations. However, the identification of these winning tickets still requires the costly train-prune-retrain process, limiting their practical benefits. In this paper, we discover for the first time that the winning tickets can be identified at the very early training stage, which we term as early-bird (EB) tickets, via low-cost training schemes (e.</description>
    </item>
    
  </channel>
</rss>